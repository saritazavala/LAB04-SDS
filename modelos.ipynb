{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 2 - Laboratorio 4\n",
    "### Sara Zavala\n",
    "### Ricardo Valenzuela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import *\n",
    "from sklearn import metrics\n",
    "from quickda.explore_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init = pd.read_csv(\"VirusSample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>api</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7ff49f2f0912352416b05c010f35f402cc79feed</td>\n",
       "      <td>IntersectRect,GetCurrentProcess,GetVersion</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50cc6c99ec285d0db45dde07d8fdc18d9098c5b6</td>\n",
       "      <td>GetCaretBlinkTime,CountClipboardFormats,GetCon...</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f77c6bd4aebacd1a01d02e0cb20642ebf2d32929</td>\n",
       "      <td>VarR8Pow,GetClipboardViewer,GetInputDesktop,Ge...</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349c367c5b88fbb6cafae5d7109588d7250e16b5</td>\n",
       "      <td>SetTraceCallback,CopyAcceleratorTableW,GetProc...</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>021f4aa86b520e1d606ab26699c35546bcd00c27</td>\n",
       "      <td>SHLoadNonloadedIconOverlayIdentifiers,VarUI8Fr...</td>\n",
       "      <td>Virus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file  \\\n",
       "0  7ff49f2f0912352416b05c010f35f402cc79feed   \n",
       "1  50cc6c99ec285d0db45dde07d8fdc18d9098c5b6   \n",
       "2  f77c6bd4aebacd1a01d02e0cb20642ebf2d32929   \n",
       "3  349c367c5b88fbb6cafae5d7109588d7250e16b5   \n",
       "4  021f4aa86b520e1d606ab26699c35546bcd00c27   \n",
       "\n",
       "                                                 api  class  \n",
       "0         IntersectRect,GetCurrentProcess,GetVersion  Virus  \n",
       "1  GetCaretBlinkTime,CountClipboardFormats,GetCon...  Virus  \n",
       "2  VarR8Pow,GetClipboardViewer,GetInputDesktop,Ge...  Virus  \n",
       "3  SetTraceCallback,CopyAcceleratorTableW,GetProc...  Virus  \n",
       "4  SHLoadNonloadedIconOverlayIdentifiers,VarUI8Fr...  Virus  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis exploratorio preliminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtypes</th>\n",
       "      <th>count</th>\n",
       "      <th>null_sum</th>\n",
       "      <th>null_pct</th>\n",
       "      <th>nunique</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>api</th>\n",
       "      <td>object</td>\n",
       "      <td>9795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2980</td>\n",
       "      <td>?changeGuard@QMetaObject@@SAXPAPAVQObject@@PAV...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>wvsprintfW,VarDecFix,GetUserDefaultLangID,GetC...</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>object</td>\n",
       "      <td>9795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>Adware</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Worms</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>object</td>\n",
       "      <td>9795</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9795</td>\n",
       "      <td>0003103d2781125e0fd463e5042d3f26cb932f01</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>fffa9307c95121145fb056748bc830d1724f81d1</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       dtypes  count  null_sum  null_pct  nunique  \\\n",
       "api    object   9795         0       0.0     2980   \n",
       "class  object   9795         0       0.0       13   \n",
       "file   object   9795         0       0.0     9795   \n",
       "\n",
       "                                                     min 25% 50% 75%  \\\n",
       "api    ?changeGuard@QMetaObject@@SAXPAPAVQObject@@PAV...   -   -   -   \n",
       "class                                             Adware   -   -   -   \n",
       "file            0003103d2781125e0fd463e5042d3f26cb932f01   -   -   -   \n",
       "\n",
       "                                                     max mean median std skew  \n",
       "api    wvsprintfW,VarDecFix,GetUserDefaultLangID,GetC...    -      -   -    -  \n",
       "class                                              Worms    -      -   -    -  \n",
       "file            fffa9307c95121145fb056748bc830d1724f81d1    -      -   -    -  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explore(df_init, method=\"summarize\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9795 entries, 0 to 9794\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   file    9795 non-null   object\n",
      " 1   api     9795 non-null   object\n",
      " 2   class   9795 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 229.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df_init.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solo tenemos 3 columnas iniciales, por lo que de momento no es necesario hacer un pandas profiling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trojan        6153\n",
       "Virus         2367\n",
       "Backdoor       447\n",
       "Worms          441\n",
       "Adware         222\n",
       "Agent          102\n",
       "Downloader      31\n",
       "Spyware         11\n",
       "Ransomware      10\n",
       "Riskware         4\n",
       "Dropper          4\n",
       "Crypt            2\n",
       "Keylogger        1\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 13 diferentes clases, sin embargo, vemos tambien que el dataset esta muy desbalanceado, la diferencia entre su clase con mas incidencias con la de menos es demasiado grande. Decidimos quitar aquellas clases que tienen menos de 100 incidencias, esto ya que no queremos agregar overfitting al intentar balancear demasiado las clases que tienen pocos registros. Tambien tomamos esta decision ya que se querian dejar solamente las clases que tiene el articulo de referencia, esto con el fin de hacer una mejor comparacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_init.drop(df_init[df_init[\"class\"] == \"Downloader\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Ransomware\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Spyware\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Riskware\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Dropper\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Crypt\"].index, inplace=True)\n",
    "df_init.drop(df_init[df_init[\"class\"] == \"Keylogger\"].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trojan      6153\n",
       "Virus       2367\n",
       "Backdoor     447\n",
       "Worms        441\n",
       "Adware       222\n",
       "Agent        102\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformamos la clase a una variable cuantitativa para facilidad al crear modelos:  \n",
    "    - 0: Adware  \n",
    "    - 1: Agent  \n",
    "    - 2: Backdoor  \n",
    "    - 3: Trojan  \n",
    "    - 4: Virus  \n",
    "    - 5: Worms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df_init['class'] = le.fit_transform(df_init['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    6153\n",
       "4    2367\n",
       "2     447\n",
       "5     441\n",
       "0     222\n",
       "1     102\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_init[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos conteo de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_init.loc[:, df_init.columns != 'class']\n",
    "target = df_init[\"class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4887</td>\n",
       "      <td>1240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3104</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9414</td>\n",
       "      <td>2501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2027</td>\n",
       "      <td>2245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83</td>\n",
       "      <td>2127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9727</th>\n",
       "      <td>2242</td>\n",
       "      <td>1611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9728</th>\n",
       "      <td>3233</td>\n",
       "      <td>2059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9729</th>\n",
       "      <td>8390</td>\n",
       "      <td>2708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9730</th>\n",
       "      <td>7864</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>7221</td>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9732 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "0     4887  1240\n",
       "1     3104   599\n",
       "2     9414  2501\n",
       "3     2027  2245\n",
       "4       83  2127\n",
       "...    ...   ...\n",
       "9727  2242  1611\n",
       "9728  3233  2059\n",
       "9729  8390  2708\n",
       "9730  7864  1209\n",
       "9731  7221  2299\n",
       "\n",
       "[9732 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = pd.DataFrame(features,dtype=str)\n",
    "features_df.apply(le.fit_transform)\n",
    "\n",
    "features_df = pd.DataFrame(features_df.apply(le.fit_transform).values[:,:])\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancemos un poco los datos, siempre manteniendo el patron para no agregar overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanio completo del df tras preprocesamiento:  9732\n",
      "Antes del oversampling:  Counter({3: 6153, 4: 2367, 2: 447, 5: 441, 0: 222, 1: 102})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(\"Tamanio completo del df tras preprocesamiento: \", len(df_init))\n",
    "print(\"Antes del oversampling: \",Counter(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Luego del oversampling:  Counter({3: 6153, 4: 3000, 2: 2500, 5: 2250, 0: 1750, 1: 1500})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy = {0: 1750, 1:1500, 2:2500,4:3000, 5:2250})\n",
    "\n",
    "x, y = sm.fit_resample(features_df, target)\n",
    "\n",
    "oversampled_data = x\n",
    "\n",
    "print(\"Luego del oversampling: \",Counter(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora escalamos los datos con el fin de no ver tanta diferencia entre datos con las estadisticas y graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.502209</td>\n",
       "      <td>0.421912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.318981</td>\n",
       "      <td>0.203811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.967424</td>\n",
       "      <td>0.850970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.208303</td>\n",
       "      <td>0.763865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.723716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17148</th>\n",
       "      <td>0.286507</td>\n",
       "      <td>0.498809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17149</th>\n",
       "      <td>0.592745</td>\n",
       "      <td>0.229330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17150</th>\n",
       "      <td>0.930737</td>\n",
       "      <td>0.498809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17151</th>\n",
       "      <td>0.063611</td>\n",
       "      <td>0.798571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17152</th>\n",
       "      <td>0.543212</td>\n",
       "      <td>0.514120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1\n",
       "0      0.502209  0.421912\n",
       "1      0.318981  0.203811\n",
       "2      0.967424  0.850970\n",
       "3      0.208303  0.763865\n",
       "4      0.008529  0.723716\n",
       "...         ...       ...\n",
       "17148  0.286507  0.498809\n",
       "17149  0.592745  0.229330\n",
       "17150  0.930737  0.498809\n",
       "17151  0.063611  0.798571\n",
       "17152  0.543212  0.514120\n",
       "\n",
       "[17153 rows x 2 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x)\n",
    "features_df = pd.DataFrame(scaler.transform(x))\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente dividimos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, target_train, target_test = train_test_split(features_df, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#Creacion de modelo\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de entrenamiento es de:  0.7976180561339219\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Prueba para el conjunto de entrenamiento, esto se hace para luego comprar resultados con el conjunto de test y determinar si hay overfitting o no.\n",
    "predict_train = knn.predict(features_train)\n",
    "print(\"El valor de accuracy con la data de entrenamiento es de: \", metrics.accuracy_score(predict_train, target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de test es de:  0.7201710066070734\n"
     ]
    }
   ],
   "source": [
    "#Prueba para el conjunto de entrenamiento, esto se hace para luego comprar resultados con el conjunto de test y determinar si hay overfitting o no.\n",
    "predict_test = knn.predict(features_test)\n",
    "print(\"El valor de accuracy con la data de test es de: \", metrics.accuracy_score(predict_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.63      0.62       516\n",
      "           1       0.72      0.82      0.77       437\n",
      "           2       0.87      0.94      0.91       756\n",
      "           3       0.73      0.78      0.76      1875\n",
      "           4       0.66      0.52      0.58       918\n",
      "           5       0.64      0.56      0.60       644\n",
      "\n",
      "    accuracy                           0.72      5146\n",
      "   macro avg       0.71      0.71      0.71      5146\n",
      "weighted avg       0.71      0.72      0.71      5146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "#Matriz de confusion\n",
    "print(classification_report(target_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 325,   16,    8,   86,   59,   22],\n",
       "       [   8,  359,    4,   39,   22,    5],\n",
       "       [   4,    1,  713,   32,    4,    2],\n",
       "       [  73,   76,   38, 1469,  114,  105],\n",
       "       [  94,   34,   44,  199,  477,   70],\n",
       "       [  24,   14,   10,  183,   50,  363]], dtype=int64)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = confusion_matrix(target_test, predict_test)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71690258, 0.72522898, 0.69775187, 0.70274771, 0.69941715,\n",
       "       0.7194005 , 0.71440466, 0.71166667, 0.69166667, 0.70416667])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "cross_val_score(knn, features_train, target_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo considerablemente bueno, vemos que sus mejores clasificaciones ocurren con Agent, Backdoor y Trojan, sin embargo, para las demas clases su valor de precicion no estan bueno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clfTree = tree.DecisionTreeClassifier()\n",
    "clfTree.fit(features_train,target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de entrenamiento es de:  0.9987507287415675\n"
     ]
    }
   ],
   "source": [
    "#Prueba para el conjunto de entrenamiento, esto se hace para luego comprar resultados con el conjunto de test y determinar si hay overfitting o no.\n",
    "predict_train = clfTree.predict(features_train)\n",
    "print(\"El valor de accuracy con la data de entrenamiento es de: \", metrics.accuracy_score(predict_train, target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de test es de:  0.7848814613291877\n"
     ]
    }
   ],
   "source": [
    "predict_test = clfTree.predict(features_test)\n",
    "print(\"El valor de accuracy con la data de test es de: \", metrics.accuracy_score(predict_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.67       516\n",
      "           1       0.74      0.76      0.75       437\n",
      "           2       0.93      0.93      0.93       756\n",
      "           3       0.86      0.84      0.85      1875\n",
      "           4       0.69      0.69      0.69       918\n",
      "           5       0.66      0.68      0.67       644\n",
      "\n",
      "    accuracy                           0.78      5146\n",
      "   macro avg       0.76      0.76      0.76      5146\n",
      "weighted avg       0.79      0.78      0.79      5146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import *\n",
    "#Matriz de confusion\n",
    "print(classification_report(target_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 348,    7,    4,   27,   96,   34],\n",
       "       [  13,  334,    1,   44,   33,   12],\n",
       "       [   4,    2,  704,   29,   14,    3],\n",
       "       [  42,   57,   26, 1582,   72,   96],\n",
       "       [  91,   35,   18,   64,  635,   75],\n",
       "       [  27,   14,    5,   85,   77,  436]], dtype=int64)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf = confusion_matrix(target_test, predict_test)\n",
    "cf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78517902, 0.76852623, 0.77601998, 0.77268943, 0.77685262,\n",
       "       0.7868443 , 0.77019151, 0.75666667, 0.77333333, 0.7775    ])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "cross_val_score(clfTree, features_train, target_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro mejor modelo, vemos que tiene una media de acurracy de 0.78 el cual es de nuestros mejores resultados, la mejor clase que categorizo correctamiente fue la de Backdoor seguida por trojan, y la de peor clasificacion fue Advware. Sin embargo, vemos una gran variedad de precision al comparar todas las clases, vemos que la mayoria de confusiones suceden con la clase virus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Creacion de modelo\n",
    "naiveBB = MultinomialNB()\n",
    "naiveBB.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de entrenamiento es de:  0.3562921629049721\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "#Prueba para el conjunto de entrenamiento, esto se hace para luego comprar resultados con el conjunto de test y determinar si hay overfitting o no.\n",
    "predict_train = naiveBB.predict(features_train)\n",
    "print(\"El valor de accuracy con la data de entrenamiento es de: \", metrics.accuracy_score(predict_train, target_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de accuracy con la data de test es de:  0.36436066848037313\n"
     ]
    }
   ],
   "source": [
    "#Prueba para el conjunto de entrenamiento, esto se hace para luego comprar resultados con el conjunto de test y determinar si hay overfitting o no.\n",
    "predict_test = naiveBB.predict(features_test)\n",
    "print(\"El valor de accuracy con la data de test es de: \", metrics.accuracy_score(predict_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       516\n",
      "           1       0.00      0.00      0.00       437\n",
      "           2       0.00      0.00      0.00       756\n",
      "           3       0.36      1.00      0.53      1875\n",
      "           4       0.00      0.00      0.00       918\n",
      "           5       0.00      0.00      0.00       644\n",
      "\n",
      "    accuracy                           0.36      5146\n",
      "   macro avg       0.06      0.17      0.09      5146\n",
      "weighted avg       0.13      0.36      0.19      5146\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zephyrus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Zephyrus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "C:\\Users\\Zephyrus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning:\n",
      "\n",
      "Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Matriz de confusion\n",
    "print(classification_report(target_test, predict_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3438801 , 0.36136553, 0.33555371, 0.367194  , 0.34471274,\n",
       "       0.34471274, 0.35470441, 0.38666667, 0.37083333, 0.35333333])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "cross_val_score(naiveBB, features_train, target_train, scoring='accuracy', cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro peor modelo con referencia, este modelo tomo como unica clasificacion valida los ataques de tipo Trojan y clasifico a todas las observaciones como la misma, esto causa que nuestro accuracy sea solamente de 0.333, la metrica de recall para esta catergoria es de 1 pero el f1 y precision son muy bajos. Esto sucede ya que el modelo se sobre ajusto al dataset y tomo la via facil de clasificar como un solo tipo a todos los registros, este modelo no se tomara para la comparacion con los resultados del articulo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿se lograron obtener mejores métricas que las obtenidas en el artículo para la clasificación de malware?\n",
    "\n",
    "A simple vista podemos ver que en su mayoria todas las clases de nuestro mejor modelo tuvieron un peor resultado que los del articulo, solo el caso de Troyan fue el que tuvo mejores resultados. Esto se puede deber a una variedad de factores, sin embargo, el principal problema que encontramos al trabajar con la RAW data fue que estaba muy desbalanceada, la diferencia entre la clase que tenia mas incidencias y la de menor era demasiada, nosotros intentamos balancearla con overfitting pero esto pudo causar que el modelo se sobre ajustara a los datos (como en el caso de bayes ingenuo). A pesar de que los datos con los que se trabajo estaban bastante completos para unos casos no fue suficiente. Sin emabargo, creemos que apesar te no lograr los mejores resultados nos acercamos bastante apesar de contar con las complicaciones antes mencionadas. Tambien creemos que aplicando otras tecnicas de procesamiento de datos hubiesemos obtenido aun mejores resultados, se planteo usar algun bag of words, pero esto no iba con los objetivos del laboratorio ya que el principal objetivo del lab era clasificar los ataques con base a la secuencia de APIs que se llaman no solo las APIs en especifico.\n",
    "\n",
    "- 0: Adware  \n",
    "- 1: Agent  \n",
    "- 2: Backdoor  \n",
    "- 3: Trojan  \n",
    "- 4: Virus  \n",
    "- 5: Worms  \n",
    "\n",
    "Nuestro mejor modelo (clasification tree):  \n",
    "\n",
    " \t \tprecision    recall  f1-score   support\n",
    "\n",
    "           0       0.66      0.67      0.67       516\n",
    "           1       0.74      0.76      0.75       437\n",
    "           2       0.93      0.93      0.93       756\n",
    "           3       0.86      0.84      0.85      1875\n",
    "           4       0.69      0.69      0.69       918\n",
    "           5       0.66      0.68      0.67       644\n",
    "\n",
    "Resultados articulo:\n",
    "\n",
    "\t\t\t\t\tHGB \tRF  \tSVM  \tXGB  \n",
    "\t\tMalware Types \t\tF1-score F1-Score F1-Score F1-Score  \n",
    "\t\tAdware \t\t\t0.89 \t0.92 \t0.96 \t0.91  \n",
    "\t\tAgent \t\t\t0.91 \t0.91 \t0.91 \t0.91  \n",
    "\t\tBackdoor \t\t0.95 \t0.95 \t0.94 \t0.95  \n",
    "\t\tTrojan \t\t\t0.75 \t0.72 \t0.76 \t0.76  \n",
    "\t\tVirus \t\t\t0.95 \t0.79 \t0.97 \t0.98  \n",
    "\t\tWorms \t\t\t0.92 \t0.68 \t0.92 \t0.90  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c22766af836425960ae160e7be50936e507f0f35951e7536c143bdebf186894a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
